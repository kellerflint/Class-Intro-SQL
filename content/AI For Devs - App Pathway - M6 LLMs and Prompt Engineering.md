# M6 LLMs and Prompt Engineering

### LLM Settings
Read / Watch: [LLM Settings | Prompt Engineering Guide](https://www.promptingguide.ai/introduction/settings).
- *Understanding these settings will be important to getting the level of consistency and variability you want out of your LLMs.*

### Prompting Techniques
Review at least the following techniques from the [Prompt Engineering Guide](https://www.promptingguide.ai/). This site is a great reference for working with LLMs.
- Read / Watch: [Zero-Shot Prompting | Prompt Engineering Guide](https://www.promptingguide.ai/techniques/zeroshot)
- Read / Watch: [Few-Shot Prompting | Prompt Engineering Guide](https://www.promptingguide.ai/techniques/fewshot)
- Read / Watch: [Chain-of-Thought Prompting | Prompt Engineering Guide](https://www.promptingguide.ai/techniques/cot)
- Read / Watch: [Prompt Chaining | Prompt Engineering Guide](https://www.promptingguide.ai/techniques/prompt_chaining)
- *Understanding at least these approaches is necessary for effective application prompting.*

### Read: [RISEN: 5 Steps to Build Context-Rich AI Prompts | ClickUp](https://clickup.com/general-resources/playbooks/ai-prompts)
- *One of the most effective frameworks for getting LLMs to behave.*

### Read: [Chat Templates](https://huggingface.co/docs/transformers/main/chat_templating#introduction)
- *Chat templates are extremely common most applications make use of them. **Only the introduction is required reading.***


### Back: [[AI For Devs - AI Apps Pathway]]